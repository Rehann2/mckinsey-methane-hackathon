{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kaancaylan/Desktop/HEC/mckinsey_hackathon/methane-hackathon'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run once before notebook \n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import LoadData\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaancaylan/.pyenv/versions/3.9.6/envs/myenv/lib/python3.9/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data = LoadData(metadata_path=\"data/train_data/metadata.csv\",\n",
    "                image_data_path=\"data/train_data/\")\n",
    "\n",
    "X, y = data.get_train_data()\n",
    "X = data.normalize_data(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=True)\n",
    "X_train_aug, y_train_aug = data.augment_data(X_train, y_train, n_epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 690945 (2.64 MB)\n",
      "Trainable params: 690945 (2.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional layers\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flatten the output for fully connected layers\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # Fully connected layers\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')  # Use 'sigmoid' for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Use 'binary_crossentropy' for binary classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary to view the architecture\n",
    "model.summary()\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,           \n",
    "    restore_best_weights=True)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "269/269 [==============================] - 8s 28ms/step - loss: 0.4949 - accuracy: 0.7639 - val_loss: 0.3184 - val_accuracy: 0.8643\n",
      "Epoch 2/100\n",
      "269/269 [==============================] - 7s 28ms/step - loss: 0.2959 - accuracy: 0.8809 - val_loss: 0.1807 - val_accuracy: 0.9280\n",
      "Epoch 3/100\n",
      "269/269 [==============================] - 8s 28ms/step - loss: 0.1626 - accuracy: 0.9352 - val_loss: 0.0828 - val_accuracy: 0.9712\n",
      "Epoch 4/100\n",
      "269/269 [==============================] - 8s 28ms/step - loss: 0.0769 - accuracy: 0.9710 - val_loss: 0.0532 - val_accuracy: 0.9819\n",
      "Epoch 5/100\n",
      "269/269 [==============================] - 8s 28ms/step - loss: 0.0573 - accuracy: 0.9812 - val_loss: 0.0579 - val_accuracy: 0.9786\n",
      "Epoch 6/100\n",
      "269/269 [==============================] - 8s 28ms/step - loss: 0.0407 - accuracy: 0.9865 - val_loss: 0.0490 - val_accuracy: 0.9819\n",
      "Epoch 7/100\n",
      "269/269 [==============================] - 8s 29ms/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 0.0379 - val_accuracy: 0.9851\n",
      "Epoch 8/100\n",
      "269/269 [==============================] - 8s 29ms/step - loss: 0.0228 - accuracy: 0.9922 - val_loss: 0.0342 - val_accuracy: 0.9879\n",
      "Epoch 9/100\n",
      "269/269 [==============================] - 8s 30ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.0937 - val_accuracy: 0.9721\n",
      "Epoch 10/100\n",
      "269/269 [==============================] - 8s 29ms/step - loss: 0.0277 - accuracy: 0.9902 - val_loss: 0.0580 - val_accuracy: 0.9800\n",
      "Epoch 11/100\n",
      "269/269 [==============================] - 8s 29ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0451 - val_accuracy: 0.9856\n",
      "Epoch 12/100\n",
      "269/269 [==============================] - 7s 28ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0424 - val_accuracy: 0.9870\n",
      "Epoch 13/100\n",
      "269/269 [==============================] - 8s 28ms/step - loss: 0.0158 - accuracy: 0.9934 - val_loss: 0.0407 - val_accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x296068be0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "model.fit(X_train_aug, y_train_aug, \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size, \n",
    "          validation_split=0.2,\n",
    "          callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
