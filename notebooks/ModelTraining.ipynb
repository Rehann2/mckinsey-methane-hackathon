{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Rehan Ibrahim\\\\OneDrive - HEC Paris\\\\Desktop\\\\mckinsey-methane-hackathon'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run once before notebook \n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import LoadData\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "import rasterio\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_df = pd.read_csv('data/dataset/train_data/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat        lon       \n",
       "29.631951   35.952379    21\n",
       "32.713854   44.609398    19\n",
       "33.990812   39.641866    18\n",
       "28.510000   77.442400    17\n",
       "36.596520   38.321405    15\n",
       "                         ..\n",
       "21.039986  -77.824694     1\n",
       "24.907500   67.023000     1\n",
       "23.763333   86.396667     1\n",
       "23.740000   90.595000     1\n",
       "68.570113   25.563059     1\n",
       "Length: 101, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df[['lat','lon']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_coord</th>\n",
       "      <th>plume</th>\n",
       "      <th>set</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>coord_x</th>\n",
       "      <th>coord_y</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230223</td>\n",
       "      <td>id_6675</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>31.528750</td>\n",
       "      <td>74.330625</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>images/plume/20230223_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230103</td>\n",
       "      <td>id_2542</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>35.538000</td>\n",
       "      <td>112.524000</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>images/plume/20230103_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230301</td>\n",
       "      <td>id_6546</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>21.060000</td>\n",
       "      <td>84.936667</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>images/plume/20230301_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230225</td>\n",
       "      <td>id_6084</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>26.756667</td>\n",
       "      <td>80.973333</td>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>images/plume/20230225_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230105</td>\n",
       "      <td>id_2012</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>40.770000</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>images/plume/20230105_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date id_coord plume    set        lat         lon  coord_x  coord_y  \\\n",
       "0  20230223  id_6675   yes  train  31.528750   74.330625       24       47   \n",
       "1  20230103  id_2542   yes  train  35.538000  112.524000       42       37   \n",
       "2  20230301  id_6546   yes  train  21.060000   84.936667       58       15   \n",
       "3  20230225  id_6084   yes  train  26.756667   80.973333       28       62   \n",
       "4  20230105  id_2012   yes  train  34.800000   40.770000       59       44   \n",
       "\n",
       "                                                path  \n",
       "0  images/plume/20230223_methane_mixing_ratio_id_...  \n",
       "1  images/plume/20230103_methane_mixing_ratio_id_...  \n",
       "2  images/plume/20230301_methane_mixing_ratio_id_...  \n",
       "3  images/plume/20230225_methane_mixing_ratio_id_...  \n",
       "4  images/plume/20230105_methane_mixing_ratio_id_...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['path'] = 'data/dataset/train_data/' + meta_df['path'].astype(str) \n",
    "meta_df['path'] =  meta_df['path'].astype(str) +'.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_coord</th>\n",
       "      <th>plume</th>\n",
       "      <th>set</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>coord_x</th>\n",
       "      <th>coord_y</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230223</td>\n",
       "      <td>id_6675</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>31.528750</td>\n",
       "      <td>74.330625</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>data/dataset/train_data/images/plume/20230223_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230103</td>\n",
       "      <td>id_2542</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>35.538000</td>\n",
       "      <td>112.524000</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>data/dataset/train_data/images/plume/20230103_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230301</td>\n",
       "      <td>id_6546</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>21.060000</td>\n",
       "      <td>84.936667</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>data/dataset/train_data/images/plume/20230301_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230225</td>\n",
       "      <td>id_6084</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>26.756667</td>\n",
       "      <td>80.973333</td>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>data/dataset/train_data/images/plume/20230225_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230105</td>\n",
       "      <td>id_2012</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>40.770000</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>data/dataset/train_data/images/plume/20230105_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>20230302</td>\n",
       "      <td>id_6658</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>30.965619</td>\n",
       "      <td>34.541283</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>data/dataset/train_data/images/no_plume/202303...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>20230218</td>\n",
       "      <td>id_4690</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>35.950275</td>\n",
       "      <td>40.267652</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>data/dataset/train_data/images/no_plume/202302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>20230213</td>\n",
       "      <td>id_2519</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>49.963801</td>\n",
       "      <td>6.016938</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>data/dataset/train_data/images/no_plume/202302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>20230213</td>\n",
       "      <td>id_5510</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>32.713854</td>\n",
       "      <td>44.609398</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>data/dataset/train_data/images/no_plume/202302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>20230330</td>\n",
       "      <td>id_6609</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>47.758979</td>\n",
       "      <td>27.801630</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>data/dataset/train_data/images/no_plume/202303...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date id_coord plume    set        lat         lon  coord_x  coord_y  \\\n",
       "0    20230223  id_6675   yes  train  31.528750   74.330625       24       47   \n",
       "1    20230103  id_2542   yes  train  35.538000  112.524000       42       37   \n",
       "2    20230301  id_6546   yes  train  21.060000   84.936667       58       15   \n",
       "3    20230225  id_6084   yes  train  26.756667   80.973333       28       62   \n",
       "4    20230105  id_2012   yes  train  34.800000   40.770000       59       44   \n",
       "..        ...      ...   ...    ...        ...         ...      ...      ...   \n",
       "425  20230302  id_6658    no  train  30.965619   34.541283       39       36   \n",
       "426  20230218  id_4690    no  train  35.950275   40.267652       29       28   \n",
       "427  20230213  id_2519    no  train  49.963801    6.016938       23       10   \n",
       "428  20230213  id_5510    no  train  32.713854   44.609398       55       54   \n",
       "429  20230330  id_6609    no  train  47.758979   27.801630       21       15   \n",
       "\n",
       "                                                  path  \n",
       "0    data/dataset/train_data/images/plume/20230223_...  \n",
       "1    data/dataset/train_data/images/plume/20230103_...  \n",
       "2    data/dataset/train_data/images/plume/20230301_...  \n",
       "3    data/dataset/train_data/images/plume/20230225_...  \n",
       "4    data/dataset/train_data/images/plume/20230105_...  \n",
       "..                                                 ...  \n",
       "425  data/dataset/train_data/images/no_plume/202303...  \n",
       "426  data/dataset/train_data/images/no_plume/202302...  \n",
       "427  data/dataset/train_data/images/no_plume/202302...  \n",
       "428  data/dataset/train_data/images/no_plume/202302...  \n",
       "429  data/dataset/train_data/images/no_plume/202303...  \n",
       "\n",
       "[430 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['plume'] = meta_df['plume'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_coord</th>\n",
       "      <th>plume</th>\n",
       "      <th>set</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>coord_x</th>\n",
       "      <th>coord_y</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230223</td>\n",
       "      <td>id_6675</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>31.528750</td>\n",
       "      <td>74.330625</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>data/dataset/train_data/images/plume/20230223_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230103</td>\n",
       "      <td>id_2542</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>35.538000</td>\n",
       "      <td>112.524000</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>data/dataset/train_data/images/plume/20230103_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230301</td>\n",
       "      <td>id_6546</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>21.060000</td>\n",
       "      <td>84.936667</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>data/dataset/train_data/images/plume/20230301_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230225</td>\n",
       "      <td>id_6084</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>26.756667</td>\n",
       "      <td>80.973333</td>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>data/dataset/train_data/images/plume/20230225_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230105</td>\n",
       "      <td>id_2012</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>40.770000</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>data/dataset/train_data/images/plume/20230105_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>20230302</td>\n",
       "      <td>id_6658</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>30.965619</td>\n",
       "      <td>34.541283</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>data/dataset/train_data/images/no_plume/202303...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>20230218</td>\n",
       "      <td>id_4690</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>35.950275</td>\n",
       "      <td>40.267652</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>data/dataset/train_data/images/no_plume/202302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>20230213</td>\n",
       "      <td>id_2519</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>49.963801</td>\n",
       "      <td>6.016938</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>data/dataset/train_data/images/no_plume/202302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>20230213</td>\n",
       "      <td>id_5510</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>32.713854</td>\n",
       "      <td>44.609398</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>data/dataset/train_data/images/no_plume/202302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>20230330</td>\n",
       "      <td>id_6609</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>47.758979</td>\n",
       "      <td>27.801630</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>data/dataset/train_data/images/no_plume/202303...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date id_coord  plume    set        lat         lon  coord_x  coord_y  \\\n",
       "0    20230223  id_6675      1  train  31.528750   74.330625       24       47   \n",
       "1    20230103  id_2542      1  train  35.538000  112.524000       42       37   \n",
       "2    20230301  id_6546      1  train  21.060000   84.936667       58       15   \n",
       "3    20230225  id_6084      1  train  26.756667   80.973333       28       62   \n",
       "4    20230105  id_2012      1  train  34.800000   40.770000       59       44   \n",
       "..        ...      ...    ...    ...        ...         ...      ...      ...   \n",
       "425  20230302  id_6658      0  train  30.965619   34.541283       39       36   \n",
       "426  20230218  id_4690      0  train  35.950275   40.267652       29       28   \n",
       "427  20230213  id_2519      0  train  49.963801    6.016938       23       10   \n",
       "428  20230213  id_5510      0  train  32.713854   44.609398       55       54   \n",
       "429  20230330  id_6609      0  train  47.758979   27.801630       21       15   \n",
       "\n",
       "                                                  path  \n",
       "0    data/dataset/train_data/images/plume/20230223_...  \n",
       "1    data/dataset/train_data/images/plume/20230103_...  \n",
       "2    data/dataset/train_data/images/plume/20230301_...  \n",
       "3    data/dataset/train_data/images/plume/20230225_...  \n",
       "4    data/dataset/train_data/images/plume/20230105_...  \n",
       "..                                                 ...  \n",
       "425  data/dataset/train_data/images/no_plume/202303...  \n",
       "426  data/dataset/train_data/images/no_plume/202302...  \n",
       "427  data/dataset/train_data/images/no_plume/202302...  \n",
       "428  data/dataset/train_data/images/no_plume/202302...  \n",
       "429  data/dataset/train_data/images/no_plume/202303...  \n",
       "\n",
       "[430 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rehan Ibrahim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rasterio\\__init__.py:320: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Rehan Ibrahim\\OneDrive - HEC Paris\\Desktop\\mckinsey-methane-hackathon\\notebooks\\ModelTraining.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rehan%20Ibrahim/OneDrive%20-%20HEC%20Paris/Desktop/mckinsey-methane-hackathon/notebooks/ModelTraining.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m rasterio\u001b[39m.\u001b[39mopen(\u001b[39m'\u001b[39m\u001b[39mdata/dataset/train_data/images/plume/20230223_methane_mixing_ratio_id_6675.tif\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m src:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rehan%20Ibrahim/OneDrive%20-%20HEC%20Paris/Desktop/mckinsey-methane-hackathon/notebooks/ModelTraining.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     img \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mread(\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rehan%20Ibrahim/OneDrive%20-%20HEC%20Paris/Desktop/mckinsey-methane-hackathon/notebooks/ModelTraining.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ep\u001b[39m.\u001b[39mplot_bands(img)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ep' is not defined"
     ]
    }
   ],
   "source": [
    "with rasterio.open('data/dataset/train_data/images/plume/20230223_methane_mixing_ratio_id_6675.tif') as src:\n",
    "    img = src.read(1)\n",
    "ep.plot_bands(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rehan Ibrahim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rasterio\\__init__.py:320: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_data = []\n",
    "plume_labels = []\n",
    "\n",
    "# Loop through the metadata and load images\n",
    "for index, row in meta_df.iterrows():\n",
    "    image_path = row['path']\n",
    "    plume_label = row['plume']\n",
    "\n",
    "    # Read the TIFF image using rasterio\n",
    "    try:\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image = src.read(1)  # Assuming single-band image, adjust if necessary\n",
    "            # You may want to resize or preprocess the image here if necessary\n",
    "\n",
    "        # Append the image data and plume label to their respective lists\n",
    "        image_data.append(image)\n",
    "        plume_labels.append(plume_label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image at {image_path}: {e}\")\n",
    "\n",
    "# Convert the lists into NumPy arrays\n",
    "image_data = np.array(image_data)\n",
    "plume_labels = np.array(plume_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plume_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[15373, 23745, 23745, ...,     0,     0,     0],\n",
       "        [21083, 22849, 22849, ...,     0,     0,     0],\n",
       "        [21083, 22849, 22849, ...,     0,  3348,  3348],\n",
       "        ...,\n",
       "        [49287, 49287, 43637, ..., 22215, 29933, 29933],\n",
       "        [49287, 43637, 43637, ..., 13711, 14626, 14626],\n",
       "        [49834, 48903, 48903, ..., 13711, 14626, 14626]],\n",
       "\n",
       "       [[    0,     0,     0, ...,     0,     0,     0],\n",
       "        [ 6386, 11516,  1537, ...,     0,     0,     0],\n",
       "        [ 6386, 11516,  1537, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 3878,  6976,  6548, ...,     0,     0,     0],\n",
       "        [ 3878,  6976,  6548, ...,     0,     0,     0],\n",
       "        [ 4225,     0,  4100, ...,     0,     0,     0]],\n",
       "\n",
       "       [[14118,  9487,  9487, ..., 25601, 22138, 22138],\n",
       "        [16914,  5666,  5666, ..., 30095, 26363, 26363],\n",
       "        [16914,  5666,  5666, ..., 30095, 26363, 26363],\n",
       "        ...,\n",
       "        [14918, 14918, 16676, ..., 18546,     0,     0],\n",
       "        [14918, 14918, 16676, ..., 18546,     0,     0],\n",
       "        [    0,     0,     0, ...,  6638,     0,     0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[42516, 41205, 45212, ..., 15059, 32915, 32915],\n",
       "        [    0, 48178, 45978, ..., 15059, 32915, 32915],\n",
       "        [    0, 48178, 45978, ..., 11351,  3934,  3934],\n",
       "        ...,\n",
       "        [    0,     0,     0, ...,     0,     0,     0],\n",
       "        [    0,     0,     0, ...,     0,     0,     0],\n",
       "        [    0,     0,     0, ...,     0,     0,     0]],\n",
       "\n",
       "       [[11184, 12509, 12509, ...,     0,     0,     0],\n",
       "        [11184, 12509, 12509, ...,     0,     0,     0],\n",
       "        [13173, 14030, 14030, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [27451, 27451, 27451, ...,     0,     0,     0],\n",
       "        [24843, 24843, 24843, ...,     0,     0,     0],\n",
       "        [24843, 24843, 24843, ...,     0,     0,     0]],\n",
       "\n",
       "       [[16737,     0,  7920, ..., 14995, 38241, 17538],\n",
       "        [15144, 16789, 24014, ..., 14995, 38241, 17538],\n",
       "        [15144, 16789, 24014, ...,  3623, 29676, 41046],\n",
       "        ...,\n",
       "        [    0,     0, 17724, ...,     0,     0,  1133],\n",
       "        [    0,     0, 17724, ..., 18202, 37727, 46228],\n",
       "        [    0,     0,  1945, ..., 18202, 37727, 46228]]], dtype=uint16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23457694, 0.36232547, 0.36232547, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.32170596, 0.34865339, 0.34865339, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.32170596, 0.34865339, 0.34865339, ..., 0.        ,\n",
       "         0.05108721, 0.05108721],\n",
       "        ...,\n",
       "        [0.75207141, 0.75207141, 0.66585794, ..., 0.33897917,\n",
       "         0.4567483 , 0.4567483 ],\n",
       "        [0.75207141, 0.66585794, 0.66585794, ..., 0.20921645,\n",
       "         0.22317845, 0.22317845],\n",
       "        [0.7604181 , 0.74621195, 0.74621195, ..., 0.20921645,\n",
       "         0.22317845, 0.22317845]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.09744411, 0.1757229 , 0.02345312, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.09744411, 0.1757229 , 0.02345312, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.05917449, 0.10644694, 0.09991608, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.05917449, 0.10644694, 0.09991608, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.06446937, 0.        , 0.06256199, ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.21542687, 0.14476234, 0.14476234, ..., 0.39064622,\n",
       "         0.33780423, 0.33780423],\n",
       "        [0.2580911 , 0.08645762, 0.08645762, ..., 0.45922026,\n",
       "         0.40227359, 0.40227359],\n",
       "        [0.2580911 , 0.08645762, 0.08645762, ..., 0.45922026,\n",
       "         0.40227359, 0.40227359],\n",
       "        ...,\n",
       "        [0.22763409, 0.22763409, 0.25445945, ..., 0.28299382,\n",
       "         0.        , 0.        ],\n",
       "        [0.22763409, 0.22763409, 0.25445945, ..., 0.28299382,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.10128939,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.64875257, 0.628748  , 0.6898909 , ..., 0.22978561,\n",
       "         0.50225071, 0.50225071],\n",
       "        [0.        , 0.73514916, 0.70157931, ..., 0.22978561,\n",
       "         0.50225071, 0.50225071],\n",
       "        [0.        , 0.73514916, 0.70157931, ..., 0.17320516,\n",
       "         0.06002899, 0.06002899],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.1706569 , 0.1908751 , 0.1908751 , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.1706569 , 0.1908751 , 0.1908751 , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.2010071 , 0.21408408, 0.21408408, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.41887541, 0.41887541, 0.41887541, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.37907988, 0.37907988, 0.37907988, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.37907988, 0.37907988, 0.37907988, ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.25539025, 0.        , 0.12085145, ..., 0.22880903,\n",
       "         0.58352026, 0.26761273],\n",
       "        [0.23108263, 0.25618372, 0.36643015, ..., 0.22880903,\n",
       "         0.58352026, 0.26761273],\n",
       "        [0.23108263, 0.25618372, 0.36643015, ..., 0.05528344,\n",
       "         0.45282673, 0.62632181],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.2704509 , ..., 0.        ,\n",
       "         0.        , 0.01728847],\n",
       "        [0.        , 0.        , 0.2704509 , ..., 0.27774472,\n",
       "         0.57567712, 0.70539406],\n",
       "        [0.        , 0.        , 0.0296788 , ..., 0.27774472,\n",
       "         0.57567712, 0.70539406]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = image_data.min()\n",
    "max_val = image_data.max()\n",
    "\n",
    "# Normalize the image data\n",
    "normalized_image_data = (image_data - min_val) / (max_val - min_val)\n",
    "normalized_image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (258, 64, 64)\n",
      "X_test shape: (172, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "X = normalized_image_data\n",
    "y = plume_labels\n",
    "\n",
    "\n",
    "#X = [np.transpose(image, (1, 2, 0)) for image in X]\n",
    "\n",
    "#X = np.array(X)\n",
    "np.random.seed(101)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42,shuffle=True)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rehan Ibrahim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rasterio\\__init__.py:320: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = LoadData(metadata_path=\"data/dataset/train_data/metadata.csv\",\n",
    "                image_data_path=\"data/dataset/train_data/\")\n",
    "\n",
    "X_train_aug, X_test, y_train_aug, y_test = data.prep_data(normalize=True, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 31, 31, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 690945 (2.64 MB)\n",
      "Trainable params: 690945 (2.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional layers\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flatten the output for fully connected layers\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # Fully connected layers\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')  # Use 'sigmoid' for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Use 'binary_crossentropy' for binary classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary to view the architecture\n",
    "model.summary()\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,           \n",
    "    restore_best_weights=True)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.5214 - accuracy: 0.7314 - val_loss: 0.3727 - val_accuracy: 0.8308\n",
      "Epoch 2/100\n",
      "260/260 [==============================] - 7s 29ms/step - loss: 0.3289 - accuracy: 0.8659 - val_loss: 0.2224 - val_accuracy: 0.9115\n",
      "Epoch 3/100\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.2100 - accuracy: 0.9232 - val_loss: 0.1611 - val_accuracy: 0.9298\n",
      "Epoch 4/100\n",
      "260/260 [==============================] - 7s 29ms/step - loss: 0.1134 - accuracy: 0.9597 - val_loss: 0.1170 - val_accuracy: 0.9548\n",
      "Epoch 5/100\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.0771 - accuracy: 0.9714 - val_loss: 0.1206 - val_accuracy: 0.9543\n",
      "Epoch 6/100\n",
      "260/260 [==============================] - 8s 30ms/step - loss: 0.0536 - accuracy: 0.9830 - val_loss: 0.0560 - val_accuracy: 0.9793\n",
      "Epoch 7/100\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.0531 - accuracy: 0.9829 - val_loss: 0.0487 - val_accuracy: 0.9798\n",
      "Epoch 8/100\n",
      "260/260 [==============================] - 8s 30ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.0848 - val_accuracy: 0.9692\n",
      "Epoch 9/100\n",
      "260/260 [==============================] - 8s 30ms/step - loss: 0.0227 - accuracy: 0.9917 - val_loss: 0.0620 - val_accuracy: 0.9769\n",
      "Epoch 10/100\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.0353 - accuracy: 0.9883 - val_loss: 0.0442 - val_accuracy: 0.9822\n",
      "Epoch 11/100\n",
      "260/260 [==============================] - 8s 30ms/step - loss: 0.0177 - accuracy: 0.9935 - val_loss: 0.3683 - val_accuracy: 0.9173\n",
      "Epoch 12/100\n",
      "260/260 [==============================] - 8s 31ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 0.0709 - val_accuracy: 0.9817\n",
      "Epoch 13/100\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 14/100\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.0497 - val_accuracy: 0.9817\n",
      "Epoch 15/100\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.0812 - val_accuracy: 0.9745\n",
      "Epoch 16/100\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 0.0561 - val_accuracy: 0.9750\n",
      "Epoch 17/100\n",
      "260/260 [==============================] - 8s 30ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.0662 - val_accuracy: 0.9798\n",
      "Epoch 18/100\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0477 - val_accuracy: 0.9846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x295eaaac0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "model.fit(X_train_aug, y_train_aug, \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size, \n",
    "          validation_split=0.2,\n",
    "          callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate External features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_coord</th>\n",
       "      <th>plume</th>\n",
       "      <th>set</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>coord_x</th>\n",
       "      <th>coord_y</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-23</td>\n",
       "      <td>id_6675</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>31.528750</td>\n",
       "      <td>74.330625</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>images/plume/20230223_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>id_2542</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>35.538000</td>\n",
       "      <td>112.524000</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>images/plume/20230103_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>id_6546</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>21.060000</td>\n",
       "      <td>84.936667</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>images/plume/20230301_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-25</td>\n",
       "      <td>id_6084</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>26.756667</td>\n",
       "      <td>80.973333</td>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>images/plume/20230225_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>id_2012</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>40.770000</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>images/plume/20230105_methane_mixing_ratio_id_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>id_6658</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>30.965619</td>\n",
       "      <td>34.541283</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>images/no_plume/20230302_methane_mixing_ratio_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>2023-02-18</td>\n",
       "      <td>id_4690</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>35.950275</td>\n",
       "      <td>40.267652</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>images/no_plume/20230218_methane_mixing_ratio_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>id_2519</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>49.963801</td>\n",
       "      <td>6.016938</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>images/no_plume/20230213_methane_mixing_ratio_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>id_5510</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>32.713854</td>\n",
       "      <td>44.609398</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>images/no_plume/20230213_methane_mixing_ratio_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>id_6609</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>47.758979</td>\n",
       "      <td>27.801630</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>images/no_plume/20230330_methane_mixing_ratio_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date id_coord plume    set        lat         lon  coord_x  coord_y  \\\n",
       "0   2023-02-23  id_6675   yes  train  31.528750   74.330625       24       47   \n",
       "1   2023-01-03  id_2542   yes  train  35.538000  112.524000       42       37   \n",
       "2   2023-03-01  id_6546   yes  train  21.060000   84.936667       58       15   \n",
       "3   2023-02-25  id_6084   yes  train  26.756667   80.973333       28       62   \n",
       "4   2023-01-05  id_2012   yes  train  34.800000   40.770000       59       44   \n",
       "..         ...      ...   ...    ...        ...         ...      ...      ...   \n",
       "425 2023-03-02  id_6658    no  train  30.965619   34.541283       39       36   \n",
       "426 2023-02-18  id_4690    no  train  35.950275   40.267652       29       28   \n",
       "427 2023-02-13  id_2519    no  train  49.963801    6.016938       23       10   \n",
       "428 2023-02-13  id_5510    no  train  32.713854   44.609398       55       54   \n",
       "429 2023-03-30  id_6609    no  train  47.758979   27.801630       21       15   \n",
       "\n",
       "                                                  path  \n",
       "0    images/plume/20230223_methane_mixing_ratio_id_...  \n",
       "1    images/plume/20230103_methane_mixing_ratio_id_...  \n",
       "2    images/plume/20230301_methane_mixing_ratio_id_...  \n",
       "3    images/plume/20230225_methane_mixing_ratio_id_...  \n",
       "4    images/plume/20230105_methane_mixing_ratio_id_...  \n",
       "..                                                 ...  \n",
       "425  images/no_plume/20230302_methane_mixing_ratio_...  \n",
       "426  images/no_plume/20230218_methane_mixing_ratio_...  \n",
       "427  images/no_plume/20230213_methane_mixing_ratio_...  \n",
       "428  images/no_plume/20230213_methane_mixing_ratio_...  \n",
       "429  images/no_plume/20230330_methane_mixing_ratio_...  \n",
       "\n",
       "[430 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>coord_x</th>\n",
       "      <th>coord_y</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.528750</td>\n",
       "      <td>74.330625</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.538000</td>\n",
       "      <td>112.524000</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.060000</td>\n",
       "      <td>84.936667</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.756667</td>\n",
       "      <td>80.973333</td>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.800000</td>\n",
       "      <td>40.770000</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon  coord_x  coord_y  year  month  day\n",
       "0  31.528750   74.330625       24       47  2023      2   23\n",
       "1  35.538000  112.524000       42       37  2023      1    3\n",
       "2  21.060000   84.936667       58       15  2023      3    1\n",
       "3  26.756667   80.973333       28       62  2023      2   25\n",
       "4  34.800000   40.770000       59       44  2023      1    5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_dates(df, date_col=\"date\"):\n",
    "    df['year'] = df[date_col].dt.year\n",
    "    df['month'] = df[date_col].dt.month\n",
    "    df['day'] = df[date_col].dt.day\n",
    "    return df.drop(\"date\", axis=1)\n",
    "\n",
    "meta_df = encode_dates(data.meta_df.copy())\n",
    "external_data = meta_df[[\"lat\", \"lon\", \"coord_x\", \"coord_y\", \"year\", \"month\", \"day\"]]\n",
    "external_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 31, 31, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92672 (362.00 KB)\n",
      "Trainable params: 92672 (362.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional layers\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Flatten the output for fully connected layers\n",
    "    layers.Flatten(),\n",
    "])\n",
    "\n",
    "# Metadata input layer\n",
    "metadata_input = tf.keras.layers.Input(shape=(external_data.shape[1]))\n",
    "\n",
    "# Get the output of the CNN model\n",
    "cnn_output = model.output\n",
    "\n",
    "# Concatenate the flattened output with the metadata input\n",
    "concatenated = tf.keras.layers.concatenate([cnn_output, metadata_input])\n",
    "\n",
    "# Add fully connected layers after concatenation\n",
    "x = layers.Dense(128, activation='relu')(concatenated)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the combined model\n",
    "combined_model = tf.keras.Model(inputs=[model.input, metadata_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(\n",
    "    loss='binary_crossentropy',  \n",
    "    optimizer='adam',  \n",
    "    metrics=['accuracy'],  \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 2s 108ms/step - loss: 17.7812 - accuracy: 0.4660 - val_loss: 10.2391 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 10.6059 - accuracy: 0.4903 - val_loss: 6.7134 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 10.0554 - accuracy: 0.4709 - val_loss: 2.4589 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 8.0796 - accuracy: 0.4757 - val_loss: 2.4245 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.6305 - accuracy: 0.4709 - val_loss: 0.6390 - val_accuracy: 0.6923\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 4.3026 - accuracy: 0.5583 - val_loss: 0.8122 - val_accuracy: 0.3846\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 2.8962 - accuracy: 0.5340 - val_loss: 1.7454 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 2.5628 - accuracy: 0.5874 - val_loss: 0.7246 - val_accuracy: 0.5577\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 2.6759 - accuracy: 0.5049 - val_loss: 0.5900 - val_accuracy: 0.7115\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 1.7058 - accuracy: 0.5971 - val_loss: 0.9122 - val_accuracy: 0.5577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c7529efe50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "combined_model.fit(\n",
    "    [X_train, external_data],  \n",
    "    y_train,  \n",
    "    epochs=10,  \n",
    "    batch_size=32,  \n",
    "    validation_split=0.2,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.68729198e-01, 0.00000000e+00, 2.86045074e-02, ...,\n",
       "        2.62588680e-01, 2.08794102e-01, 0.00000000e+00],\n",
       "       [7.48590350e-01, 0.00000000e+00, 5.52959293e-02, ...,\n",
       "        3.76618624e-01, 1.77203745e-01, 0.00000000e+00],\n",
       "       [5.79662204e-01, 0.00000000e+00, 2.95998156e-02, ...,\n",
       "        2.83273876e-01, 1.04130976e-01, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.89571306e-02, 0.00000000e+00, 1.00764260e-03, ...,\n",
       "        2.88628995e-01, 1.17505126e-01, 0.00000000e+00],\n",
       "       [1.48526883e+00, 0.00000000e+00, 7.41923526e-02, ...,\n",
       "        3.52907896e-01, 9.56372321e-02, 0.00000000e+00],\n",
       "       [3.13669652e-01, 0.00000000e+00, 6.02501445e-03, ...,\n",
       "        5.27367711e-01, 2.22998023e-01, 0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply threshold to obtain binary predictions (0 or 1)\n",
    "threshold = 0.5\n",
    "binary_predictions = (predictions >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Rehan Ibrahim\\OneDrive - HEC Paris\\Desktop\\mckinsey-methane-hackathon\\notebooks\\ModelTraining.ipynb Cell 28\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rehan%20Ibrahim/OneDrive%20-%20HEC%20Paris/Desktop/mckinsey-methane-hackathon/notebooks/ModelTraining.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rehan%20Ibrahim/OneDrive%20-%20HEC%20Paris/Desktop/mckinsey-methane-hackathon/notebooks/ModelTraining.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, binary_predictions)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rehan%20Ibrahim/OneDrive%20-%20HEC%20Paris/Desktop/mckinsey-methane-hackathon/notebooks/ModelTraining.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rehan Ibrahim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Rehan Ibrahim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Rehan Ibrahim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "accuracy = accuracy_score(y_test, binary_predictions)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional layers\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Flatten the output for fully connected layers\n",
    "    layers.Flatten(),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "input_1d = tf.keras.layers.Input(shape=(external_data.shape[1]))  # Adjust the shape as needed\n",
    "\n",
    "# Concatenate the flattened output and the 1-dimensional input\n",
    "X_concat = tf.keras.layers.concatenate([model.output, input_1d])\n",
    "\n",
    "# Add fully connected layers after concatenation\n",
    "concat_model = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "# Create the model\n",
    "combined_model = tf.keras.Model(inputs=[model.input, input_1d])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
